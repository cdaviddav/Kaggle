{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build basic ML models incl. pipeline and validation strategy\n",
    "Build , test and evaluate multiple basic ML models regarding\n",
    "- which kinds of models have the best performance?\n",
    "- which metrics are requested by the Kaggle competition?\n",
    "- which settings in the data preprocessing stage increate the model performance?\n",
    "- which validation strategy works the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.4.3\n",
      "numpy version: 1.21.5\n",
      "sklearn version: 1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna version: 2.10.1\n",
      "mlflow version: 1.28.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "# numpy: support for large, multi-dimensional arrays and matrices and high-level mathematical functions\n",
    "import numpy as np\n",
    "print(\"numpy version: {}\". format(np.__version__))\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit, train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix, roc_auc_score\n",
    "print(\"sklearn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "import optuna\n",
    "print(\"optuna version: {}\". format(optuna.__version__))\n",
    "\n",
    "import mlflow\n",
    "from mlflow.utils.mlflow_tags import MLFLOW_PARENT_RUN_ID\n",
    "from mlflow.tracking import MlflowClient\n",
    "print(\"mlflow version: {}\". format(mlflow.__version__))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "import yaml\n",
    "with open('ml_parameter.yaml') as file:\n",
    "  config_data= yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "try:\n",
    "    experiment = client.create_experiment(config_data[\"experiment_name\"])\n",
    "except:\n",
    "    experiment = client.get_experiment_by_name(config_data[\"experiment_name\"]).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_bins_fare, n_bins_age, transform_skewed_features_flag, ohe_min_frequency, ohe_max_categories, feature_selection_low_variance_flag, correlation):\n",
    "        self.n_bins_fare=n_bins_fare\n",
    "        self.n_bins_age=n_bins_age\n",
    "        self.transform_skewed_features_flag=transform_skewed_features_flag\n",
    "        self.ohe_min_frequency=ohe_min_frequency\n",
    "        self.ohe_max_categories=ohe_max_categories\n",
    "        self.feature_selection_low_variance_flag=feature_selection_low_variance_flag\n",
    "        self.correlation=correlation\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        df_train = pd.read_pickle('../03_DataPreprocessing/df_train_prepared_unfinished.pkl')\n",
    "        df_test = pd.read_pickle('../03_DataPreprocessing/df_test_prepared_unfinished.pkl')\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def bining(self, df_train, df_test):\n",
    "        df_train['Fare_bin'] = pd.qcut(df_train['Fare'], self.n_bins_fare, labels=False)\n",
    "        df_test['Fare_bin'] = pd.qcut(df_test['Fare'], self.n_bins_fare, labels=False)\n",
    "\n",
    "        df_train['Age_bin'] = pd.qcut(df_train['Age'], self.n_bins_age, labels=False)\n",
    "        df_test['Age_bin'] = pd.qcut(df_test['Age'], self.n_bins_age, labels=False)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def transform_skewed_features(self, df_train, df_test):\n",
    "        df_train[\"Fare\"] = df_train[\"Fare\"].apply(np.log)\n",
    "        df_test[\"Fare\"] = df_test[\"Fare\"].apply(np.log)\n",
    "\n",
    "        # the not transformed data that contains 0\n",
    "        # after the transformation we have -inf values that have to be replaced by 0\n",
    "        df_train[\"Fare\"][np.isneginf(df_train[\"Fare\"])]=0\n",
    "        df_test[\"Fare\"][np.isneginf(df_test[\"Fare\"])]=0\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def transform_categoric_OneHotEncoder(self, df_train, df_test):\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False, drop=\"if_binary\", min_frequency=self.ohe_min_frequency, max_categories=self.ohe_max_categories)\n",
    "        cat_vars = df_train.dtypes[df_train.dtypes == \"object\"].index\n",
    "\n",
    "        ohe_train = pd.DataFrame(enc.fit_transform(df_train[cat_vars]), columns=enc.get_feature_names())\n",
    "        df_train = pd.concat([df_train, ohe_train], axis=1).drop(cat_vars, axis=1)\n",
    "\n",
    "        ohe_test = pd.DataFrame(enc.transform(df_test[cat_vars]), columns=enc.get_feature_names())\n",
    "        df_test = pd.concat([df_test, ohe_test], axis=1).drop(cat_vars, axis=1)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def feature_selection_low_variance(self, df_train, df_test):\n",
    "        from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "        # remove all features that are either one or zero in more than 95% of the samples\n",
    "        sel = VarianceThreshold(threshold=(.95 * (1 - .95)))\n",
    "        sel_features = list(df_train)\n",
    "\n",
    "        # remove the label from the list of columns\n",
    "        sel_features.remove(\"Survived\")\n",
    "\n",
    "        # fit the VarianceThreshold object to the training data\n",
    "        sel.fit(df_train[sel_features])\n",
    "\n",
    "        # get the column names after the variance threshold reduction\n",
    "        sel_features_reduced = [sel_features[i] for i in sel.get_support(indices=True)]\n",
    "\n",
    "        # create the training and test dataset by transform the datasets to the variance threshold object\n",
    "        df_train_ = pd.DataFrame(sel.transform(df_train[sel_features]), columns=sel_features_reduced)\n",
    "        # dont forget to join the label back to the training data\n",
    "        df_train = pd.concat([df_train_, df_train[\"Survived\"]], axis=1)\n",
    "        df_test = pd.DataFrame(sel.transform(df_test[sel_features]), columns=sel_features_reduced)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def feature_selection_correlation(self, df_train, df_test):\n",
    "        corr_matrix = df_train.corr().abs()\n",
    "\n",
    "        # Select upper triangle of correlation matrix\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "        # Find features with correlation higher than 0.9 or lower -0.9\n",
    "        to_drop = [column for column in upper.columns if any((upper[column] > self.correlation) | (upper[column] < -self.correlation))]\n",
    "\n",
    "        df_train.drop(to_drop, axis=1, inplace=True)\n",
    "        df_test.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def transform(self, X=None, y=None):\n",
    "        df_train, df_test = self.load_data()\n",
    "\n",
    "        df_train, df_test = self.bining(df_train, df_test)\n",
    "\n",
    "        if self.transform_skewed_features_flag == True:\n",
    "            df_train, df_test = self.transform_skewed_features(df_train, df_test)\n",
    "        \n",
    "        df_train.drop(['PassengerId', 'Name', 'dataset', 'First'], axis=1, inplace=True)\n",
    "        df_test.drop(['PassengerId', 'Name',  'dataset', 'Survived', 'First'], axis=1, inplace=True)\n",
    "\n",
    "        df_train, df_test = self.transform_categoric_OneHotEncoder(df_train, df_test)\n",
    "\n",
    "        if self.feature_selection_low_variance_flag == True:\n",
    "            df_train, df_test = self.feature_selection_low_variance(df_train, df_test)\n",
    "\n",
    "        df_train, df_test = self.feature_selection_correlation(df_train, df_test)\n",
    "\n",
    "        return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross validation\n",
    "cv = ShuffleSplit(\n",
    "    n_splits = 10,\n",
    "    test_size = 0.2,\n",
    "    random_state = config_data[\"RANDOM_STATE\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial, model_type, child_run, x_train):   \n",
    "\n",
    "\n",
    "    ''' columnprep '''\n",
    "    columnprep__transformers_num = trial.suggest_categorical(\"columnprep__transformers_num\", [\"StandardScaler\", \"MinMaxScaler\"])\n",
    "\n",
    "    transformer_not_num = [x for x in list(x_train) if (x.startswith(\"x\") & x[1].isnumeric())]\n",
    "    transformer_num = [x for x in list(x_train) if x not in transformer_not_num]\n",
    "\n",
    "    if columnprep__transformers_num == \"StandardScaler\":\n",
    "        col_transform = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('num', StandardScaler(), transformer_num)\n",
    "                    ], remainder='passthrough'\n",
    "                )\n",
    "    elif columnprep__transformers_num == \"MinMaxScaler\":\n",
    "        col_transform = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', MinMaxScaler(), transformer_num)\n",
    "            ], remainder='passthrough'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    ''' algo '''\n",
    "    if model_type == 'svm':\n",
    "        svm_kernel = trial.suggest_categorical('svm_kernel', config_data[\"svm_kernel\"])\n",
    "        svm_C = trial.suggest_float('svm_C', config_data[\"svm_C\"][0], config_data[\"svm_C\"][1], log=True)\n",
    "        svm_degree = trial.suggest_discrete_uniform('svm_degree', config_data[\"svm_degree\"][0], config_data[\"svm_degree\"][1], config_data[\"svm_degree\"][2])\n",
    "        \n",
    "        model = SVC(\n",
    "            kernel=svm_kernel,\n",
    "            C=svm_C,\n",
    "            degree=svm_degree,\n",
    "            probability=True,\n",
    "            random_state=config_data[\"RANDOM_STATE\"]\n",
    "        )\n",
    "\n",
    "        client.log_param(child_run.info.run_id, \"svm_kernel\", svm_kernel)\n",
    "        client.log_param(child_run.info.run_id, \"svm_C\", svm_C)\n",
    "        client.log_param(child_run.info.run_id, \"svm_degree\", svm_degree)\n",
    "    \n",
    "\n",
    "    if model_type == 'logistic-regression':\n",
    "        lr_C = trial.suggest_float(\"lr_C\", config_data[\"lr_C\"][0], config_data[\"lr_C\"][1], log=True)\n",
    "        lr_penalty = trial.suggest_categorical('lr_penalty', config_data[\"lr_penalty\"])\n",
    "        if lr_penalty == 'l1':\n",
    "            lr_solver = 'saga'\n",
    "        else:\n",
    "            lr_solver = 'lbfgs'\n",
    "        \n",
    "        model = LogisticRegression(\n",
    "            C=lr_C,\n",
    "            penalty=lr_penalty,\n",
    "            solver=lr_solver,\n",
    "            random_state=config_data[\"RANDOM_STATE\"],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        client.log_param(child_run.info.run_id, \"lr_C\", lr_C)\n",
    "        client.log_param(child_run.info.run_id, \"lr_penalty\", lr_penalty)\n",
    "        client.log_param(child_run.info.run_id, \"lr_solver\", lr_solver)\n",
    "\n",
    "\n",
    "    if model_type == 'decision-tree':\n",
    "        dt_max_depth = trial.suggest_int('dt_max_depth', config_data[\"dt_max_depth\"][0], x_train.shape[1])\n",
    "        dt_criterion = trial.suggest_categorical(\"dt_criterion\", config_data[\"dt_criterion\"])\n",
    "        dt_max_leaf_nodes = trial.suggest_int(\"dt_max_leaf_nodes\", config_data[\"dt_max_leaf_nodes\"][0], config_data[\"dt_max_leaf_nodes\"][1])\n",
    "        \n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=dt_max_depth,\n",
    "            criterion=dt_criterion,\n",
    "            max_leaf_nodes=dt_max_leaf_nodes,\n",
    "            random_state=config_data[\"RANDOM_STATE\"]\n",
    "          )\n",
    "    \n",
    "        client.log_param(child_run.info.run_id, \"dt_max_depth\", dt_max_depth)\n",
    "        client.log_param(child_run.info.run_id, \"dt_criterion\", dt_criterion)\n",
    "        client.log_param(child_run.info.run_id, \"dt_max_leaf_nodes\", dt_max_leaf_nodes)\n",
    "    \n",
    "    \n",
    "    client.log_param(child_run.info.run_id, \"algo\", model.__class__.__name__)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('columnprep', col_transform),\n",
    "        ('algo', model)\n",
    "    ])\n",
    "\n",
    "            \n",
    "    return pipeline, child_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(x_train, y_train, y_validate, y_validate_pred, y_validate_scores, pipeline, child_run):\n",
    "    \"\"\"\n",
    "    evaluate the classification model with\n",
    "    - classification report\n",
    "    - precision-recall-curve\n",
    "    - ROC curve\n",
    "    \"\"\"\n",
    "\n",
    "    def plot_learning_curve(pipeline, x_train, y_train):\n",
    "\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            pipeline,\n",
    "            x_train,\n",
    "            y_train,\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            train_sizes=np.linspace(.1, 1.0, 8)\n",
    "            )\n",
    "\n",
    "\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel(\"Training examples\")\n",
    "        ax1.set_ylabel(\"Score\")\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "        ax1.grid()\n",
    "\n",
    "        ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                        train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                        color=\"r\")\n",
    "        ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                        test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "        ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                label=\"Training score\")\n",
    "        ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                label=\"Cross-validation score\")\n",
    "\n",
    "        ax1.legend(loc=\"best\")\n",
    "        ax1.set_title(\"Difference between training and CV: \"\\\n",
    "            + str(round(test_scores_mean[7] / train_scores_mean[7] * 100, 2))\\\n",
    "            + \"%\")\n",
    "        client.log_figure(child_run.info.run_id, fig1, 'plot_learning_curve.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def plot_confusion_matrix(y_validate, y_validate_pred):\n",
    "        group_names = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"]\n",
    "        group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                        confusion_matrix(y_validate, y_validate_pred).flatten()]\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                             confusion_matrix(y_validate, y_validate_pred).flatten()/np.sum(confusion_matrix(y_validate, y_validate_pred))]\n",
    "        labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "                  zip(group_names,group_counts,group_percentages)]\n",
    "        labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        sns.heatmap(confusion_matrix(y_validate, y_validate_pred), annot=labels, fmt=\"\", cmap='Blues')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        client.log_figure(child_run.info.run_id, fig2, 'plot_confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def plot_precision_recall_vs_threshold(y_validate, y_scores, child_run):\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_validate, y_scores)\n",
    "\n",
    "        # convert to f score\n",
    "        fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        client.log_metric(child_run.info.run_id, \"f1_score\", round(fscore[ix], 5))\n",
    "\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        ax3.plot(thresholds, precisions[:-1], \"b\", label=\"Precision\")\n",
    "        ax3.plot(thresholds, recalls[:-1], \"g\", label=\"Recall\")\n",
    "        ax3.plot(thresholds, fscore[:-1], \"r\", label=\"F1 Score\")\n",
    "        ax3.axvline(x=thresholds[ix], color='red', linestyle='--')\n",
    "        plt.axhline(y=precisions[ix], color='b', linestyle='--')\n",
    "        plt.axhline(y=recalls[ix], color='g', linestyle='--')\n",
    "        ax3.set_xlabel(\"Threshold\")\n",
    "        ax3.legend(loc=\"upper left\")\n",
    "        ax3.set_ylim([0,1])\n",
    "        client.log_figure(child_run.info.run_id, fig3, 'plot_f1.png')\n",
    "        plt.close()\n",
    "\n",
    "        fig4, ax4 = plt.subplots()\n",
    "        ax4.plot(recalls, precisions, marker='.', label='Logistic')\n",
    "        ax4.scatter(recalls[ix], precisions[ix], 200, marker='o', color='red', label='Best')\n",
    "        ax4.set_xlabel('Recall')\n",
    "        ax4.set_ylabel('Precision')\n",
    "        client.log_figure(child_run.info.run_id, fig4, 'plot_precision_recall.png')\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    def plot_roc_curve(y_validate, y_scores, child_run):\n",
    "        fpr, tpr, thresholds = roc_curve(y_validate, y_scores)\n",
    "\n",
    "        roc_auc = round(roc_auc_score(y_validate, y_scores), 3)\n",
    "        \n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "\n",
    "        fig5, ax5 = plt.subplots()\n",
    "        ax5.plot(fpr, tpr, linewidth=2)\n",
    "        ax5.plot([0,1], [0,1], 'k--')\n",
    "        ax5.axis([0,1,0,1])\n",
    "        ax5.scatter(fpr[optimal_idx], tpr[optimal_idx], 200, marker='o', color='red', label='Best')\n",
    "        ax5.set_xlabel('False Positive Rate')\n",
    "        ax5.set_ylabel('True Positive Rate')\n",
    "        client.log_figure(child_run.info.run_id, fig5, 'plot_roc_curve.png')\n",
    "        plt.close()\n",
    "\n",
    "        client.log_metric(child_run.info.run_id, \"roc_auc\", roc_auc)\n",
    "\n",
    "        \n",
    "\n",
    "    plot_confusion_matrix(y_validate, y_validate_pred)\n",
    "    plot_precision_recall_vs_threshold(y_validate, y_validate_scores, child_run)\n",
    "    plot_roc_curve(y_validate, y_validate_scores, child_run)\n",
    "    plot_learning_curve(pipeline, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    \n",
    "    def __init__(self, model_type, parent_run):\n",
    "        self.best_model = None\n",
    "        self._model = None\n",
    "        \n",
    "        self.best_x_train = None\n",
    "        self._x_train = None\n",
    "        self.best_x_validate = None\n",
    "        self._x_validate = None\n",
    "        self.best_y_train = None\n",
    "        self._y_train = None\n",
    "        self.best_y_validate = None\n",
    "        self._y_validate = None\n",
    "        self.best_x_test = None\n",
    "        self._x_test = None\n",
    "        \n",
    "        self.model_type = model_type\n",
    "        self.parent_run = parent_run\n",
    "\n",
    "    \n",
    "    def __call__(self, trial):\n",
    "\n",
    "        child_run = client.create_run(\n",
    "            experiment_id=experiment,\n",
    "            tags={\n",
    "                MLFLOW_PARENT_RUN_ID: parent_run.info.run_id\n",
    "            }\n",
    "        )\n",
    "\n",
    "        n_bins_fare=trial.suggest_int('preprocessing_n_bins_fare', 5, 15)\n",
    "        n_bins_age=trial.suggest_int('preprocessing_n_bins_age', 5, 15)\n",
    "        transform_skewed_features_flag=trial.suggest_categorical(\"preprocessing_transform_skewed_features_flag\", [True, False])\n",
    "        ohe_min_frequency=trial.suggest_float(\"preprocessing_ohe_min_frequency\", 0, 0.2, log=False)\n",
    "        ohe_max_categories=trial.suggest_int('preprocessing_ohe_max_categories', 20, 100)\n",
    "        feature_selection_low_variance_flag=trial.suggest_categorical(\"preprocessing_feature_selection_low_variance_flag\", [True, False])\n",
    "        correlation=trial.suggest_float(\"preprocessing_correlation\", 0.7, 0.95, log=False)\n",
    "    \n",
    "        datapreprocessing = DataPreprocessing(\n",
    "            n_bins_fare=n_bins_fare,\n",
    "            n_bins_age=n_bins_age,\n",
    "            transform_skewed_features_flag=transform_skewed_features_flag,\n",
    "            ohe_min_frequency=ohe_min_frequency,\n",
    "            ohe_max_categories=ohe_max_categories,\n",
    "            feature_selection_low_variance_flag=feature_selection_low_variance_flag,\n",
    "            correlation=correlation\n",
    "            )\n",
    "\n",
    "        client.log_param(child_run.info.run_id, \"preprocessing_n_bins_fare\", n_bins_fare)\n",
    "        client.log_param(child_run.info.run_id, \"preprocessing_n_bins_age\", n_bins_age)\n",
    "\n",
    "        df_train, df_test = datapreprocessing.transform()\n",
    "        \n",
    "        # split the training and test dataset to the input features (x_train, x_test) and the survival class (y_train)\n",
    "        y_train = df_train['Survived']\n",
    "        x_train = df_train.drop(['Survived'], axis=1)\n",
    "        x_test = df_test\n",
    "\n",
    "        x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=config_data[\"RANDOM_STATE\"])\n",
    "        self._x_train, self._x_validate, self._y_train, self._y_validate, self._x_test = x_train, x_validate, y_train, y_validate, x_test\n",
    "\n",
    "\n",
    "        pipeline = create_model(trial, self.model_type, self.child_run, x_train)\n",
    "        self._model = pipeline\n",
    "\n",
    "        score = cross_val_score(\n",
    "            pipeline,\n",
    "            x_train,\n",
    "            y_train,\n",
    "            cv=cv,\n",
    "            scoring=\"accuracy\",\n",
    "            n_jobs=-1\n",
    "        ).mean()\n",
    "\n",
    "        client.log_metric(child_run.info.run_id, \"cv_score\", score)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def callback(self, study, trial):\n",
    "        if study.best_trial == trial:\n",
    "            self.best_model = self._model\n",
    "\n",
    "            self.best_x_train = self._x_train\n",
    "            self.best_x_validate = self._x_validate\n",
    "            self.best_y_train = self._y_train\n",
    "            self.best_y_validate = self._y_validate\n",
    "            self.best_x_test = self._x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(best_model, x_test, parent_run):\n",
    "    # predict the test values with the training classification model\n",
    "    y_pred = best_model.predict(x_test).astype(int)\n",
    "    \n",
    "    df_submission = pd.read_csv(\"../01_RawData/gender_submission.csv\")\n",
    "    df_submission['Survived'] = y_pred\n",
    "    \n",
    "    df_submission.to_csv('submissions/%s.csv'%parent_run.info.run_id, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-27 21:20:39,244]\u001b[0m A new study created in memory with name: no-name-1cbc65b1-efed-4be2-b298-2a4342a5f28c\u001b[0m\n",
      "\u001b[33m[W 2022-10-27 21:20:39,506]\u001b[0m Trial 0 failed because of the following error: AttributeError(\"'Objective' object has no attribute 'child_run'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_10308\\917840987.py\", line 63, in __call__\n",
      "    pipeline = create_model(trial, self.model_type, self.child_run, x_train)\n",
      "AttributeError: 'Objective' object has no attribute 'child_run'\u001b[0m\n",
      "\u001b[33m[W 2022-10-27 21:20:39,568]\u001b[0m Trial 2 failed because of the following error: AttributeError(\"'Objective' object has no attribute 'child_run'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_10308\\917840987.py\", line 63, in __call__\n",
      "    pipeline = create_model(trial, self.model_type, self.child_run, x_train)\n",
      "AttributeError: 'Objective' object has no attribute 'child_run'\u001b[0m\n",
      "\u001b[33m[W 2022-10-27 21:20:39,570]\u001b[0m Trial 3 failed because of the following error: AttributeError(\"'Objective' object has no attribute 'child_run'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_10308\\917840987.py\", line 63, in __call__\n",
      "    pipeline = create_model(trial, self.model_type, self.child_run, x_train)\n",
      "AttributeError: 'Objective' object has no attribute 'child_run'\u001b[0m\n",
      "\u001b[33m[W 2022-10-27 21:20:39,618]\u001b[0m Trial 1 failed because of the following error: AttributeError(\"'Objective' object has no attribute 'child_run'\")\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_10308\\917840987.py\", line 63, in __call__\n",
      "    pipeline = create_model(trial, self.model_type, self.child_run, x_train)\n",
      "AttributeError: 'Objective' object has no attribute 'child_run'\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Objective' object has no attribute 'child_run'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\Data Science Projects\\90_Kaggle\\titanic\\04_MachineLearningModels\\titanic_BasicModels_V3-1.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m objective \u001b[39m=\u001b[39m Objective(model_type, parent_run)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   sampler \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mTPESampler(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   objective,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   n_trials\u001b[39m=\u001b[39;49mconfig_data[\u001b[39m\"\u001b[39;49m\u001b[39mN_TRAILS\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   timeout\u001b[39m=\u001b[39;49mconfig_data[\u001b[39m\"\u001b[39;49m\u001b[39mTIMEOUT\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   callbacks\u001b[39m=\u001b[39;49m[objective\u001b[39m.\u001b[39;49mcallback]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m   )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(study\u001b[39m.\u001b[39mbest_value)\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 400\u001b[0m _optimize(\n\u001b[0;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    410\u001b[0m )\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py:106\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[39m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m                     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n\u001b[1;32m--> 106\u001b[0m                         f\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    108\u001b[0m                 futures\u001b[39m.\u001b[39madd(\n\u001b[0;32m    109\u001b[0m                     executor\u001b[39m.\u001b[39msubmit(\n\u001b[0;32m    110\u001b[0m                         _optimize_sequential,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m                     )\n\u001b[0;32m    122\u001b[0m                 )\n\u001b[0;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py:264\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch):\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m trial\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    210\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32me:\\Data Science Projects\\90_Kaggle\\titanic\\04_MachineLearningModels\\titanic_BasicModels_V3-1.ipynb Cell 10\u001b[0m in \u001b[0;36mObjective.__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m x_train, x_validate, y_train, y_validate \u001b[39m=\u001b[39m train_test_split(x_train, y_train, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39mconfig_data[\u001b[39m\"\u001b[39m\u001b[39mRANDOM_STATE\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x_validate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_validate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x_test \u001b[39m=\u001b[39m x_train, x_validate, y_train, y_validate, x_test\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m pipeline \u001b[39m=\u001b[39m create_model(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchild_run, x_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m pipeline\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m score \u001b[39m=\u001b[39m cross_val_score(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     pipeline,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     x_train,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V3-1.ipynb#X12sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m )\u001b[39m.\u001b[39mmean()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Objective' object has no attribute 'child_run'"
     ]
    }
   ],
   "source": [
    "model_type='logistic-regression'\n",
    "\n",
    "parent_run = client.create_run(experiment_id=experiment)\n",
    "\n",
    "objective = Objective(model_type, parent_run)\n",
    "\n",
    "study = optuna.create_study(\n",
    "  sampler = optuna.samplers.TPESampler(),\n",
    "  direction=\"maximize\"\n",
    "  )\n",
    "\n",
    "study.optimize(\n",
    "  objective,\n",
    "  n_trials=config_data[\"N_TRAILS\"],\n",
    "  timeout=config_data[\"TIMEOUT\"],\n",
    "  n_jobs=-1,\n",
    "  callbacks=[objective.callback]\n",
    "  )\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(study.best_value)\n",
    "print(study.best_params)\n",
    "\n",
    "client.log_metric(parent_run.info.run_id, \"best_cv_score\", round(study.best_value, 3))\n",
    "# client.log_param(parent_run.info.run_id, \"transformer_num\", str(transformer_num))\n",
    "\n",
    "client.log_param(parent_run.info.run_id, \"cv_n_splits\", cv.n_splits)\n",
    "client.log_param(parent_run.info.run_id, \"cv_train_size\", cv.train_size)\n",
    "client.log_param(parent_run.info.run_id, \"cv_test_size\", cv.test_size)\n",
    "client.log_param(parent_run.info.run_id, \"cv_random_state\", cv.random_state)\n",
    "\n",
    "print(\"Log best parameters\")\n",
    "for param in study.best_params:\n",
    "  client.log_param(parent_run.info.run_id, param, study.best_params[param])\n",
    "\n",
    "\n",
    "print(\"Save best model\")\n",
    "# save the best model as file\n",
    "best_model = objective.best_model\n",
    "mlflow.sklearn.save_model(best_model, \"models/%s/\"%parent_run.info.run_id)\n",
    "\n",
    "x_train = objective.best_x_train\n",
    "y_train = objective.best_y_train\n",
    "x_validate = objective.best_x_validate\n",
    "y_validate = objective.best_y_validate\n",
    "x_test = objective.best_x_test\n",
    "\n",
    "print(\"Fit best model\")\n",
    "# fit the pipeline to compute the validation results\n",
    "best_model.fit(x_train, y_train)\n",
    "\n",
    "print(\"Create submission\")\n",
    "# create submission of best model\n",
    "create_submission(best_model, x_test, parent_run)\n",
    "\n",
    "print(\"Predict training outcome\")\n",
    "# predict the training outcome\n",
    "y_validate_pred = best_model.predict(x_validate)\n",
    "\n",
    "# predict probabilities\n",
    "y_validate_proba = best_model.predict_proba(x_validate)\n",
    "# keep probabilities for the positive outcome only\n",
    "y_validate_scores = y_validate_proba[:, 1]\n",
    "\n",
    "print(\"Evaluate model performance\")\n",
    "evaluate_model(x_train, y_train, y_validate, y_validate_pred, y_validate_scores, best_model, parent_run)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mlflow_optuna')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4aa63c7bcea9117a32328ad03333d01dc516bdcdb33b6eb92ab7a393341400f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
