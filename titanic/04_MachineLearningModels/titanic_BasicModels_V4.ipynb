{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build basic ML models incl. pipeline and validation strategy\n",
    "Build , test and evaluate multiple basic ML models regarding\n",
    "- which kinds of models have the best performance?\n",
    "- which metrics are requested by the Kaggle competition?\n",
    "- which settings in the data preprocessing stage increate the model performance?\n",
    "- which validation strategy works the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version: 1.4.3\n",
      "numpy version: 1.21.5\n",
      "sklearn version: 1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optuna version: 2.10.1\n",
      "mlflow version: 1.28.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "# numpy: support for large, multi-dimensional arrays and matrices and high-level mathematical functions\n",
    "import numpy as np\n",
    "print(\"numpy version: {}\". format(np.__version__))\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit, train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, confusion_matrix, roc_auc_score\n",
    "print(\"sklearn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "import optuna\n",
    "print(\"optuna version: {}\". format(optuna.__version__))\n",
    "\n",
    "import mlflow\n",
    "from mlflow.utils.mlflow_tags import MLFLOW_PARENT_RUN_ID\n",
    "from mlflow.tracking import MlflowClient\n",
    "print(\"mlflow version: {}\". format(mlflow.__version__))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "import yaml\n",
    "with open('ml_parameter.yaml') as file:\n",
    "  config_data= yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "try:\n",
    "    experiment = client.create_experiment(config_data[\"experiment_name\"])\n",
    "except:\n",
    "    experiment = client.get_experiment_by_name(config_data[\"experiment_name\"]).experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, trial, child_run):\n",
    "        self.n_bins_fare=None\n",
    "        self.n_bins_age=None\n",
    "        self.transform_skewed_features_flag=None\n",
    "        self.ohe_min_frequency=None\n",
    "        self.ohe_max_categories=None\n",
    "        self.feature_selection_low_variance_flag=None\n",
    "        self.correlation=None\n",
    "\n",
    "        self.trial=trial\n",
    "        self.child_run=child_run\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        df_train = pd.read_pickle('../03_DataPreprocessing/df_train_prepared_unfinished.pkl')\n",
    "        df_test = pd.read_pickle('../03_DataPreprocessing/df_test_prepared_unfinished.pkl')\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def bining(self, df_train, df_test):\n",
    "        df_train['Fare_bin'] = pd.qcut(df_train['Fare'], self.n_bins_fare, labels=False)\n",
    "        df_test['Fare_bin'] = pd.qcut(df_test['Fare'], self.n_bins_fare, labels=False)\n",
    "\n",
    "        df_train['Age_bin'] = pd.qcut(df_train['Age'], self.n_bins_age, labels=False)\n",
    "        df_test['Age_bin'] = pd.qcut(df_test['Age'], self.n_bins_age, labels=False)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def transform_skewed_features(self, df_train, df_test):\n",
    "        df_train[\"Fare\"] = df_train[\"Fare\"].apply(np.log)\n",
    "        df_test[\"Fare\"] = df_test[\"Fare\"].apply(np.log)\n",
    "\n",
    "        # the not transformed data that contains 0\n",
    "        # after the transformation we have -inf values that have to be replaced by 0\n",
    "        df_train[\"Fare\"][np.isneginf(df_train[\"Fare\"])]=0\n",
    "        df_test[\"Fare\"][np.isneginf(df_test[\"Fare\"])]=0\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def transform_categoric_OneHotEncoder(self, df_train, df_test):\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc = OneHotEncoder(handle_unknown='ignore', sparse=False, drop=\"if_binary\", min_frequency=self.ohe_min_frequency, max_categories=self.ohe_max_categories)\n",
    "        cat_vars = df_train.dtypes[df_train.dtypes == \"object\"].index\n",
    "\n",
    "        ohe_train = pd.DataFrame(enc.fit_transform(df_train[cat_vars]), columns=enc.get_feature_names())\n",
    "        df_train = pd.concat([df_train, ohe_train], axis=1).drop(cat_vars, axis=1)\n",
    "\n",
    "        ohe_test = pd.DataFrame(enc.transform(df_test[cat_vars]), columns=enc.get_feature_names())\n",
    "        df_test = pd.concat([df_test, ohe_test], axis=1).drop(cat_vars, axis=1)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def feature_selection_low_variance(self, df_train, df_test):\n",
    "        from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "        # remove all features that are either one or zero in more than 95% of the samples\n",
    "        sel = VarianceThreshold(threshold=(.95 * (1 - .95)))\n",
    "        sel_features = list(df_train)\n",
    "\n",
    "        # remove the label from the list of columns\n",
    "        sel_features.remove(\"Survived\")\n",
    "\n",
    "        # fit the VarianceThreshold object to the training data\n",
    "        sel.fit(df_train[sel_features])\n",
    "\n",
    "        # get the column names after the variance threshold reduction\n",
    "        sel_features_reduced = [sel_features[i] for i in sel.get_support(indices=True)]\n",
    "\n",
    "        # create the training and test dataset by transform the datasets to the variance threshold object\n",
    "        df_train_ = pd.DataFrame(sel.transform(df_train[sel_features]), columns=sel_features_reduced)\n",
    "        # dont forget to join the label back to the training data\n",
    "        df_train = pd.concat([df_train_, df_train[\"Survived\"]], axis=1)\n",
    "        df_test = pd.DataFrame(sel.transform(df_test[sel_features]), columns=sel_features_reduced)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "    def feature_selection_correlation(self, df_train, df_test):\n",
    "        corr_matrix = df_train.corr().abs()\n",
    "\n",
    "        # Select upper triangle of correlation matrix\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "        # Find features with correlation higher than 0.9 or lower -0.9\n",
    "        to_drop = [column for column in upper.columns if any((upper[column] > self.correlation) | (upper[column] < -self.correlation))]\n",
    "\n",
    "        df_train.drop(to_drop, axis=1, inplace=True)\n",
    "        df_test.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "        return df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def transform(self, X=None, y=None):\n",
    "\n",
    "        self.n_bins_fare=self.trial.suggest_int('preprocessing_n_bins_fare', 5, 15)\n",
    "        self.n_bins_age=self.trial.suggest_int('preprocessing_n_bins_age', 5, 15)\n",
    "        self.transform_skewed_features_flag=self.trial.suggest_categorical(\"preprocessing_transform_skewed_features_flag\", [True, False])\n",
    "        self.ohe_min_frequency=self.trial.suggest_float(\"preprocessing_ohe_min_frequency\", 0, 0.2, log=False)\n",
    "        self.ohe_max_categories=self.trial.suggest_int('preprocessing_ohe_max_categories', 20, 100)\n",
    "        self.feature_selection_low_variance_flag=self.trial.suggest_categorical(\"preprocessing_feature_selection_low_variance_flag\", [True, False])\n",
    "        self.correlation=self.trial.suggest_float(\"preprocessing_correlation\", 0.7, 0.95, log=False)\n",
    "\n",
    "        client.log_param(self.child_run.info.run_id, \"preprocessing_n_bins_fare\", self.n_bins_fare)\n",
    "        client.log_param(self.child_run.info.run_id, \"preprocessing_n_bins_age\", self.n_bins_age)\n",
    "        client.log_param(self.child_run.info.run_id, \"preprocessing_transform_skewed_features_flag\", self.transform_skewed_features_flag)\n",
    "        client.log_param(self.child_run.info.run_id, \"preprocessing_ohe_min_frequency\", self.ohe_min_frequency)\n",
    "        client.log_param(self.child_run.info.run_id, \"preprocessing_ohe_max_categories\", self.ohe_max_categories)\n",
    "        client.log_param(self.child_run.info.run_id, \"preprocessing_feature_selection_low_variance_flag\", self.feature_selection_low_variance_flag)\n",
    "        client.log_param(self.child_run.info.run_id, \"preprocessing_correlation\", self.correlation)\n",
    "\n",
    "\n",
    "        df_train, df_test = self.load_data()\n",
    "\n",
    "        df_train, df_test = self.bining(df_train, df_test)\n",
    "\n",
    "        if self.transform_skewed_features_flag == True:\n",
    "            df_train, df_test = self.transform_skewed_features(df_train, df_test)\n",
    "        \n",
    "        df_train.drop(['PassengerId', 'Name', 'dataset', 'First'], axis=1, inplace=True)\n",
    "        df_test.drop(['PassengerId', 'Name',  'dataset', 'Survived', 'First'], axis=1, inplace=True)\n",
    "\n",
    "        df_train, df_test = self.transform_categoric_OneHotEncoder(df_train, df_test)\n",
    "\n",
    "        if self.feature_selection_low_variance_flag == True:\n",
    "            df_train, df_test = self.feature_selection_low_variance(df_train, df_test)\n",
    "\n",
    "        df_train, df_test = self.feature_selection_correlation(df_train, df_test)\n",
    "\n",
    "        # split the training and test dataset to the input features (x_train, x_test) and the survival class (y_train)\n",
    "        y_train = df_train['Survived']\n",
    "        x_train = df_train.drop(['Survived'], axis=1)\n",
    "        x_test = df_test\n",
    "\n",
    "        x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=config_data[\"RANDOM_STATE\"])\n",
    "\n",
    "        return x_train, x_validate, y_train, y_validate, x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross validation\n",
    "cv = ShuffleSplit(\n",
    "    n_splits = 10,\n",
    "    test_size = 0.2,\n",
    "    random_state = config_data[\"RANDOM_STATE\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(self, trial, child_run):   \n",
    "\n",
    "\n",
    "    ''' columnprep '''\n",
    "    columnprep__transformers_num = trial.suggest_categorical(\"columnprep__transformers_num\", [\"StandardScaler\", \"MinMaxScaler\"])\n",
    "\n",
    "    transformer_not_num = [x for x in list(self._x_train) if (x.startswith(\"x\") & x[1].isnumeric())]\n",
    "    transformer_num = [x for x in list(self._x_train) if x not in transformer_not_num]\n",
    "\n",
    "    if columnprep__transformers_num == \"StandardScaler\":\n",
    "        col_transform = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('num', StandardScaler(), transformer_num)\n",
    "                    ], remainder='passthrough'\n",
    "                )\n",
    "    elif columnprep__transformers_num == \"MinMaxScaler\":\n",
    "        col_transform = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', MinMaxScaler(), transformer_num)\n",
    "            ], remainder='passthrough'\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    ''' algo '''\n",
    "    if self.model_type == 'svm':\n",
    "        svm_kernel = trial.suggest_categorical('svm_kernel', config_data[\"svm_kernel\"])\n",
    "        svm_C = trial.suggest_float('svm_C', config_data[\"svm_C\"][0], config_data[\"svm_C\"][1], log=True)\n",
    "        svm_degree = trial.suggest_discrete_uniform('svm_degree', config_data[\"svm_degree\"][0], config_data[\"svm_degree\"][1], config_data[\"svm_degree\"][2])\n",
    "        \n",
    "        model = SVC(\n",
    "            kernel=svm_kernel,\n",
    "            C=svm_C,\n",
    "            degree=svm_degree,\n",
    "            probability=True,\n",
    "            random_state=config_data[\"RANDOM_STATE\"]\n",
    "        )\n",
    "\n",
    "        client.log_param(child_run.info.run_id, \"svm_kernel\", svm_kernel)\n",
    "        client.log_param(child_run.info.run_id, \"svm_C\", svm_C)\n",
    "        client.log_param(child_run.info.run_id, \"svm_degree\", svm_degree)\n",
    "    \n",
    "\n",
    "    if self.model_type == 'logistic-regression':\n",
    "        lr_C = trial.suggest_float(\"lr_C\", config_data[\"lr_C\"][0], config_data[\"lr_C\"][1], log=True)\n",
    "        lr_penalty = trial.suggest_categorical('lr_penalty', config_data[\"lr_penalty\"])\n",
    "        if lr_penalty == 'l1':\n",
    "            lr_solver = 'saga'\n",
    "        else:\n",
    "            lr_solver = 'lbfgs'\n",
    "        \n",
    "        model = LogisticRegression(\n",
    "            C=lr_C,\n",
    "            penalty=lr_penalty,\n",
    "            solver=lr_solver,\n",
    "            random_state=config_data[\"RANDOM_STATE\"],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        client.log_param(child_run.info.run_id, \"lr_C\", lr_C)\n",
    "        client.log_param(child_run.info.run_id, \"lr_penalty\", lr_penalty)\n",
    "        client.log_param(child_run.info.run_id, \"lr_solver\", lr_solver)\n",
    "\n",
    "\n",
    "    if self.model_type == 'decision-tree':\n",
    "        dt_max_depth = trial.suggest_int('dt_max_depth', config_data[\"dt_max_depth\"][0], self._x_train.shape[1])\n",
    "        dt_criterion = trial.suggest_categorical(\"dt_criterion\", config_data[\"dt_criterion\"])\n",
    "        dt_max_leaf_nodes = trial.suggest_int(\"dt_max_leaf_nodes\", config_data[\"dt_max_leaf_nodes\"][0], config_data[\"dt_max_leaf_nodes\"][1])\n",
    "        \n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=dt_max_depth,\n",
    "            criterion=dt_criterion,\n",
    "            max_leaf_nodes=dt_max_leaf_nodes,\n",
    "            random_state=config_data[\"RANDOM_STATE\"]\n",
    "          )\n",
    "    \n",
    "        client.log_param(child_run.info.run_id, \"dt_max_depth\", dt_max_depth)\n",
    "        client.log_param(child_run.info.run_id, \"dt_criterion\", dt_criterion)\n",
    "        client.log_param(child_run.info.run_id, \"dt_max_leaf_nodes\", dt_max_leaf_nodes)\n",
    "    \n",
    "    \n",
    "    client.log_param(child_run.info.run_id, \"algo\", model.__class__.__name__)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('columnprep', col_transform),\n",
    "        ('algo', model)\n",
    "    ])\n",
    "\n",
    "            \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(x_train, y_train, y_validate, y_validate_pred, y_validate_scores, pipeline, child_run):\n",
    "    \"\"\"\n",
    "    evaluate the classification model with\n",
    "    - classification report\n",
    "    - precision-recall-curve\n",
    "    - ROC curve\n",
    "    \"\"\"\n",
    "\n",
    "    def plot_learning_curve(pipeline, x_train, y_train):\n",
    "\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            pipeline,\n",
    "            x_train,\n",
    "            y_train,\n",
    "            cv=5,\n",
    "            n_jobs=-1,\n",
    "            train_sizes=np.linspace(.1, 1.0, 8)\n",
    "            )\n",
    "\n",
    "\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.set_xlabel(\"Training examples\")\n",
    "        ax1.set_ylabel(\"Score\")\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "        ax1.grid()\n",
    "\n",
    "        ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                        train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                        color=\"r\")\n",
    "        ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                        test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "        ax1.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                label=\"Training score\")\n",
    "        ax1.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                label=\"Cross-validation score\")\n",
    "\n",
    "        ax1.legend(loc=\"best\")\n",
    "        ax1.set_title(\"Difference between training and CV: \"\\\n",
    "            + str(round(test_scores_mean[7] / train_scores_mean[7] * 100, 2))\\\n",
    "            + \"%\")\n",
    "        client.log_figure(child_run.info.run_id, fig1, 'plot_learning_curve.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def plot_confusion_matrix(y_validate, y_validate_pred):\n",
    "        group_names = [\"True Neg\", \"False Pos\", \"False Neg\", \"True Pos\"]\n",
    "        group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                        confusion_matrix(y_validate, y_validate_pred).flatten()]\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                             confusion_matrix(y_validate, y_validate_pred).flatten()/np.sum(confusion_matrix(y_validate, y_validate_pred))]\n",
    "        labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "                  zip(group_names,group_counts,group_percentages)]\n",
    "        labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        sns.heatmap(confusion_matrix(y_validate, y_validate_pred), annot=labels, fmt=\"\", cmap='Blues')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        client.log_figure(child_run.info.run_id, fig2, 'plot_confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    def plot_precision_recall_vs_threshold(y_validate, y_scores, child_run):\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_validate, y_scores)\n",
    "\n",
    "        # convert to f score\n",
    "        fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
    "        # locate the index of the largest f score\n",
    "        ix = np.argmax(fscore)\n",
    "        \n",
    "        client.log_metric(child_run.info.run_id, \"f1_score\", round(fscore[ix], 5))\n",
    "\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        ax3.plot(thresholds, precisions[:-1], \"b\", label=\"Precision\")\n",
    "        ax3.plot(thresholds, recalls[:-1], \"g\", label=\"Recall\")\n",
    "        ax3.plot(thresholds, fscore[:-1], \"r\", label=\"F1 Score\")\n",
    "        ax3.axvline(x=thresholds[ix], color='red', linestyle='--')\n",
    "        plt.axhline(y=precisions[ix], color='b', linestyle='--')\n",
    "        plt.axhline(y=recalls[ix], color='g', linestyle='--')\n",
    "        ax3.set_xlabel(\"Threshold\")\n",
    "        ax3.legend(loc=\"upper left\")\n",
    "        ax3.set_ylim([0,1])\n",
    "        client.log_figure(child_run.info.run_id, fig3, 'plot_f1.png')\n",
    "        plt.close()\n",
    "\n",
    "        fig4, ax4 = plt.subplots()\n",
    "        ax4.plot(recalls, precisions, marker='.', label='Logistic')\n",
    "        ax4.scatter(recalls[ix], precisions[ix], 200, marker='o', color='red', label='Best')\n",
    "        ax4.set_xlabel('Recall')\n",
    "        ax4.set_ylabel('Precision')\n",
    "        client.log_figure(child_run.info.run_id, fig4, 'plot_precision_recall.png')\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    def plot_roc_curve(y_validate, y_scores, child_run):\n",
    "        fpr, tpr, thresholds = roc_curve(y_validate, y_scores)\n",
    "\n",
    "        roc_auc = round(roc_auc_score(y_validate, y_scores), 3)\n",
    "        \n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "\n",
    "        fig5, ax5 = plt.subplots()\n",
    "        ax5.plot(fpr, tpr, linewidth=2)\n",
    "        ax5.plot([0,1], [0,1], 'k--')\n",
    "        ax5.axis([0,1,0,1])\n",
    "        ax5.scatter(fpr[optimal_idx], tpr[optimal_idx], 200, marker='o', color='red', label='Best')\n",
    "        ax5.set_xlabel('False Positive Rate')\n",
    "        ax5.set_ylabel('True Positive Rate')\n",
    "        client.log_figure(child_run.info.run_id, fig5, 'plot_roc_curve.png')\n",
    "        plt.close()\n",
    "\n",
    "        client.log_metric(child_run.info.run_id, \"roc_auc\", roc_auc)\n",
    "\n",
    "        \n",
    "\n",
    "    plot_confusion_matrix(y_validate, y_validate_pred)\n",
    "    plot_precision_recall_vs_threshold(y_validate, y_validate_scores, child_run)\n",
    "    plot_roc_curve(y_validate, y_validate_scores, child_run)\n",
    "    plot_learning_curve(pipeline, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    \n",
    "    def __init__(self, model_type, parent_run):\n",
    "        self.best_model = None\n",
    "        self._model = None\n",
    "        \n",
    "        self.best_x_train = None\n",
    "        self._x_train = None\n",
    "        self.best_x_validate = None\n",
    "        self._x_validate = None\n",
    "        self.best_y_train = None\n",
    "        self._y_train = None\n",
    "        self.best_y_validate = None\n",
    "        self._y_validate = None\n",
    "        self.best_x_test = None\n",
    "        self._x_test = None\n",
    "        \n",
    "        self.model_type = model_type\n",
    "        self.parent_run = parent_run\n",
    "\n",
    "    \n",
    "    def __call__(self, trial):\n",
    "\n",
    "        child_run = client.create_run(\n",
    "            experiment_id=experiment,\n",
    "            tags={\n",
    "                MLFLOW_PARENT_RUN_ID: self.parent_run.info.run_id\n",
    "            }\n",
    "        )\n",
    "    \n",
    "        datapreprocessing = DataPreprocessing(trial, child_run)\n",
    "        \n",
    "        x_train, x_validate, y_train, y_validate, x_test = datapreprocessing.transform()\n",
    "        self._x_train = x_train\n",
    "        self._x_validate = x_validate\n",
    "        self._y_train = y_train\n",
    "        self._y_validate = y_validate\n",
    "        self._x_test = x_test\n",
    "\n",
    "\n",
    "        pipeline = create_model(self, trial, child_run)\n",
    "        self._model = pipeline\n",
    "\n",
    "        score = cross_val_score(\n",
    "            pipeline,\n",
    "            self._x_train,\n",
    "            self._y_train,\n",
    "            cv=cv,\n",
    "            scoring=\"accuracy\",\n",
    "            n_jobs=-1\n",
    "        ).mean()\n",
    "\n",
    "        client.log_metric(child_run.info.run_id, \"cv_score\", score)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def callback(self, study, trial):\n",
    "        if study.best_trial == trial:\n",
    "            self.best_model = self._model\n",
    "\n",
    "            self.best_x_train = self._x_train\n",
    "            self.best_x_validate = self._x_validate\n",
    "            self.best_y_train = self._y_train\n",
    "            self.best_y_validate = self._y_validate\n",
    "            self.best_x_test = self._x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(best_model, x_test, parent_run):\n",
    "    # predict the test values with the training classification model\n",
    "    y_pred = best_model.predict(x_test).astype(int)\n",
    "    \n",
    "    df_submission = pd.read_csv(\"../01_RawData/gender_submission.csv\")\n",
    "    df_submission['Survived'] = y_pred\n",
    "    \n",
    "    df_submission.to_csv('submissions/%s.csv'%parent_run.info.run_id, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_mlrun(model_type):\n",
    "  parent_run = client.create_run(experiment_id=experiment)\n",
    "\n",
    "  objective = Objective(model_type, parent_run)\n",
    "\n",
    "  study = optuna.create_study(\n",
    "    sampler = optuna.samplers.TPESampler(),\n",
    "    direction=\"maximize\"\n",
    "    )\n",
    "\n",
    "  study.optimize(\n",
    "    objective,\n",
    "    n_trials=config_data[\"N_TRAILS\"],\n",
    "    timeout=config_data[\"TIMEOUT\"],\n",
    "    n_jobs=-1,\n",
    "    callbacks=[objective.callback]\n",
    "    )\n",
    "\n",
    "  print(\"Best trial:\")\n",
    "  print(study.best_value)\n",
    "  print(study.best_params)\n",
    "\n",
    "  client.log_metric(parent_run.info.run_id, \"best_cv_score\", round(study.best_value, 3))\n",
    "  # client.log_param(parent_run.info.run_id, \"transformer_num\", str(transformer_num))\n",
    "\n",
    "  client.log_param(parent_run.info.run_id, \"cv_n_splits\", cv.n_splits)\n",
    "  client.log_param(parent_run.info.run_id, \"cv_train_size\", cv.train_size)\n",
    "  client.log_param(parent_run.info.run_id, \"cv_test_size\", cv.test_size)\n",
    "  client.log_param(parent_run.info.run_id, \"cv_random_state\", cv.random_state)\n",
    "\n",
    "  for param in study.best_params:\n",
    "    client.log_param(parent_run.info.run_id, param, study.best_params[param])\n",
    "\n",
    "\n",
    "  # save the best model as file\n",
    "  best_model = objective.best_model\n",
    "  mlflow.sklearn.save_model(best_model, \"models/%s/\"%parent_run.info.run_id)\n",
    "\n",
    "  x_train = objective.best_x_train\n",
    "  y_train = objective.best_y_train\n",
    "  x_validate = objective.best_x_validate\n",
    "  y_validate = objective.best_y_validate\n",
    "  x_test = objective.best_x_test\n",
    "\n",
    "\n",
    "  # fit the pipeline to compute the validation results\n",
    "  best_model.fit(x_train, y_train)\n",
    "\n",
    "  # create submission of best model\n",
    "  create_submission(best_model, x_test, parent_run)\n",
    "\n",
    "\n",
    "  # predict the training outcome\n",
    "  y_validate_pred = best_model.predict(x_validate)\n",
    "\n",
    "  # predict probabilities\n",
    "  y_validate_proba = best_model.predict_proba(x_validate)\n",
    "  # keep probabilities for the positive outcome only\n",
    "  y_validate_scores = y_validate_proba[:, 1]\n",
    "\n",
    "  evaluate_model(x_train, y_train, y_validate, y_validate_pred, y_validate_scores, best_model, parent_run)\n",
    "\n",
    "  mlflow.end_run()\n",
    "\n",
    "  return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-27 21:01:15,534]\u001b[0m A new study created in memory with name: no-name-ff4dde2d-b789-4a3e-b520-b83d97d89115\u001b[0m\n",
      "\u001b[33m[W 2022-10-27 21:01:19,143]\u001b[0m Trial 3 failed because of the following error: ValueError('\\nAll the 10 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n10 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\", line 3621, in get_loc\\n    return self._engine.get_loc(casted_key)\\n  File \"pandas\\\\_libs\\\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\\n  File \"pandas\\\\_libs\\\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\\nKeyError: \\'Fare_bin\\'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\utils\\\\__init__.py\", line 416, in _get_column_indices\\n    col_idx = all_columns.get_loc(col)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\", line 3623, in get_loc\\n    raise KeyError(key) from err\\nKeyError: \\'Fare_bin\\'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 686, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\pipeline.py\", line 378, in fit\\n    Xt = self._fit(X, y, **fit_params_steps)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\pipeline.py\", line 336, in _fit\\n    X, fitted_transformer = fit_transform_one_cached(\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\joblib\\\\memory.py\", line 349, in __call__\\n    return self.func(*args, **kwargs)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\pipeline.py\", line 870, in _fit_transform_one\\n    res = transformer.fit_transform(X, y, **fit_params)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\compose\\\\_column_transformer.py\", line 670, in fit_transform\\n    self._validate_column_callables(X)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\compose\\\\_column_transformer.py\", line 357, in _validate_column_callables\\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\utils\\\\__init__.py\", line 424, in _get_column_indices\\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\\nValueError: A given column is not a column of the dataframe\\n')\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_8892\\1759756478.py\", line 44, in __call__\n",
      "    score = cross_val_score(\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 285, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 367, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 10 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3621, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas\\_libs\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'Fare_bin'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 416, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3623, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'Fare_bin'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in fit_transform\n",
      "    self._validate_column_callables(X)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 357, in _validate_column_callables\n",
      "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 424, in _get_column_indices\n",
      "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\u001b[0m\n",
      "\u001b[33m[W 2022-10-27 21:01:19,149]\u001b[0m Trial 0 failed because of the following error: ValueError('\\nAll the 10 fits failed.\\nIt is very likely that your model is misconfigured.\\nYou can try to debug the error by setting error_score=\\'raise\\'.\\n\\nBelow are more details about the failures:\\n--------------------------------------------------------------------------------\\n10 fits failed with the following error:\\nTraceback (most recent call last):\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\", line 3621, in get_loc\\n    return self._engine.get_loc(casted_key)\\n  File \"pandas\\\\_libs\\\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\\n  File \"pandas\\\\_libs\\\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\\n  File \"pandas\\\\_libs\\\\hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\\nKeyError: \\'Fare_bin\\'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\utils\\\\__init__.py\", line 416, in _get_column_indices\\n    col_idx = all_columns.get_loc(col)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\", line 3623, in get_loc\\n    raise KeyError(key) from err\\nKeyError: \\'Fare_bin\\'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\model_selection\\\\_validation.py\", line 686, in _fit_and_score\\n    estimator.fit(X_train, y_train, **fit_params)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\pipeline.py\", line 378, in fit\\n    Xt = self._fit(X, y, **fit_params_steps)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\pipeline.py\", line 336, in _fit\\n    X, fitted_transformer = fit_transform_one_cached(\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\joblib\\\\memory.py\", line 349, in __call__\\n    return self.func(*args, **kwargs)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\pipeline.py\", line 870, in _fit_transform_one\\n    res = transformer.fit_transform(X, y, **fit_params)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\compose\\\\_column_transformer.py\", line 670, in fit_transform\\n    self._validate_column_callables(X)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\compose\\\\_column_transformer.py\", line 357, in _validate_column_callables\\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\\n  File \"e:\\\\programs\\\\anaconda3\\\\envs\\\\mlflow_optuna\\\\lib\\\\site-packages\\\\sklearn\\\\utils\\\\__init__.py\", line 424, in _get_column_indices\\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\\nValueError: A given column is not a column of the dataframe\\n')\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_8892\\1759756478.py\", line 44, in __call__\n",
      "    score = cross_val_score(\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 515, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 285, in cross_validate\n",
      "    _warn_or_raise_about_fit_failures(results, error_score)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 367, in _warn_or_raise_about_fit_failures\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "ValueError: \n",
      "All the 10 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3621, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas\\_libs\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'Fare_bin'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 416, in _get_column_indices\n",
      "    col_idx = all_columns.get_loc(col)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3623, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: 'Fare_bin'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in fit_transform\n",
      "    self._validate_column_callables(X)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 357, in _validate_column_callables\n",
      "    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n",
      "  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 424, in _get_column_indices\n",
      "    raise ValueError(\"A given column is not a column of the dataframe\") from e\n",
      "ValueError: A given column is not a column of the dataframe\n",
      "\u001b[0m\n",
      "\u001b[32m[I 2022-10-27 21:01:19,216]\u001b[0m Trial 2 finished with value: 0.8307692307692308 and parameters: {'preprocessing_n_bins_fare': 14, 'preprocessing_n_bins_age': 10, 'preprocessing_transform_skewed_features_flag': True, 'preprocessing_ohe_min_frequency': 0.16032904365299555, 'preprocessing_ohe_max_categories': 24, 'preprocessing_feature_selection_low_variance_flag': True, 'preprocessing_correlation': 0.7373681513765833, 'columnprep__transformers_num': 'StandardScaler', 'lr_C': 436.7897995044893, 'lr_penalty': 'l2'}. Best is trial 2 with value: 0.8307692307692308.\u001b[0m\n",
      "\u001b[32m[I 2022-10-27 21:01:19,227]\u001b[0m Trial 1 finished with value: 0.83006993006993 and parameters: {'preprocessing_n_bins_fare': 8, 'preprocessing_n_bins_age': 7, 'preprocessing_transform_skewed_features_flag': True, 'preprocessing_ohe_min_frequency': 0.08959770095278569, 'preprocessing_ohe_max_categories': 65, 'preprocessing_feature_selection_low_variance_flag': False, 'preprocessing_correlation': 0.8541947819901967, 'columnprep__transformers_num': 'StandardScaler', 'lr_C': 240.9376184934906, 'lr_penalty': 'l1'}. Best is trial 2 with value: 0.8307692307692308.\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'Fare_bin'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 416, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 'Fare_bin'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in fit_transform\n    self._validate_column_callables(X)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 357, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 424, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Data Science Projects\\90_Kaggle\\titanic\\04_MachineLearningModels\\titanic_BasicModels_V4.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study_lr \u001b[39m=\u001b[39m create_new_mlrun(model_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlogistic-regression\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m optuna\u001b[39m.\u001b[39mvisualization\u001b[39m.\u001b[39mplot_optimization_history(study_lr)\n",
      "\u001b[1;32me:\\Data Science Projects\\90_Kaggle\\titanic\\04_MachineLearningModels\\titanic_BasicModels_V4.ipynb Cell 11\u001b[0m in \u001b[0;36mcreate_new_mlrun\u001b[1;34m(model_type)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m objective \u001b[39m=\u001b[39m Objective(model_type, parent_run)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   sampler \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39msamplers\u001b[39m.\u001b[39mTPESampler(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   objective,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   n_trials\u001b[39m=\u001b[39;49mconfig_data[\u001b[39m\"\u001b[39;49m\u001b[39mN_TRAILS\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   timeout\u001b[39m=\u001b[39;49mconfig_data[\u001b[39m\"\u001b[39;49m\u001b[39mTIMEOUT\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   callbacks\u001b[39m=\u001b[39;49m[objective\u001b[39m.\u001b[39;49mcallback]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   )\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(study\u001b[39m.\u001b[39mbest_value)\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 400\u001b[0m _optimize(\n\u001b[0;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    410\u001b[0m )\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py:106\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[39m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m                     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m completed:\n\u001b[1;32m--> 106\u001b[0m                         f\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    108\u001b[0m                 futures\u001b[39m.\u001b[39madd(\n\u001b[0;32m    109\u001b[0m                     executor\u001b[39m.\u001b[39msubmit(\n\u001b[0;32m    110\u001b[0m                         _optimize_sequential,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m                     )\n\u001b[0;32m    122\u001b[0m                 )\n\u001b[0;32m    123\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py:264\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch):\n\u001b[1;32m--> 264\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m trial\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    210\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[0;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32me:\\Data Science Projects\\90_Kaggle\\titanic\\04_MachineLearningModels\\titanic_BasicModels_V4.ipynb Cell 11\u001b[0m in \u001b[0;36mObjective.__call__\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m pipeline \u001b[39m=\u001b[39m create_model(\u001b[39mself\u001b[39m, trial, child_run)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m pipeline\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m score \u001b[39m=\u001b[39m cross_val_score(\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     pipeline,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_x_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m )\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m client\u001b[39m.\u001b[39mlog_metric(child_run\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id, \u001b[39m\"\u001b[39m\u001b[39mcv_score\u001b[39m\u001b[39m\"\u001b[39m, score)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Data%20Science%20Projects/90_Kaggle/titanic/04_MachineLearningModels/titanic_BasicModels_V4.ipynb#X13sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m score\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32me:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3621, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 136, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 163, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5198, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5206, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'Fare_bin'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 416, in _get_column_indices\n    col_idx = all_columns.get_loc(col)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3623, in get_loc\n    raise KeyError(key) from err\nKeyError: 'Fare_bin'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in fit_transform\n    self._validate_column_callables(X)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 357, in _validate_column_callables\n    transformer_to_input_indices[name] = _get_column_indices(X, columns)\n  File \"e:\\programs\\anaconda3\\envs\\mlflow_optuna\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 424, in _get_column_indices\n    raise ValueError(\"A given column is not a column of the dataframe\") from e\nValueError: A given column is not a column of the dataframe\n"
     ]
    }
   ],
   "source": [
    "study_lr = create_new_mlrun(model_type='logistic-regression')\n",
    "optuna.visualization.plot_optimization_history(study_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_svm = create_new_mlrun(model_type='svm')\n",
    "optuna.visualization.plot_optimization_history(study_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_dt = create_new_mlrun(model_type='decision-tree')\n",
    "optuna.visualization.plot_optimization_history(study_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mlflow_optuna')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4aa63c7bcea9117a32328ad03333d01dc516bdcdb33b6eb92ab7a393341400f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
